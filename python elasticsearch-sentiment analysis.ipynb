{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from elasticsearch import Elasticsearch\n",
    "import nltk\n",
    "from time import gmtime, strftime\n",
    "from pythainlp.segment import segment\n",
    "import codecs\n",
    "es = Elasticsearch(['localhost'],http_auth=('elastic', 'changeme'),port=9200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def query_item(id):\n",
    "    res = es.get(index=index, doc_type=doc_type, id=id)\n",
    "    #print(res['_source'])\n",
    "    item=res['_source']\n",
    "    content=item[0]\n",
    "    sentiment=item[1]\n",
    "    return (content,sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def token_item(content):\n",
    "    ef=es.indices.analyze(text=content,analyzer=\"thai\")\n",
    "    gc=[]\n",
    "    for ge in ef['tokens']:\n",
    "        gc.append(ge['token'])\n",
    "    return gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_words_in_tweets(tweets):\n",
    "    all_words = []\n",
    "    for (words, sentiment) in tweets:\n",
    "      all_words.extend(words)\n",
    "    return all_words\n",
    "\n",
    "def get_word_features(wordlist):\n",
    "    wordlist = nltk.FreqDist(wordlist)\n",
    "    word_features = wordlist.keys()\n",
    "    return word_features\n",
    "\n",
    "def extract_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains(%s)' % word] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains(%s)' % word] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_max_id(index):\n",
    "    res = es.search(index=index, \n",
    "                            body={  \"stored_fields\": [ \"_uid\"],\n",
    "                                        \"query\": {\"match_all\": {}  },\n",
    "                                        \"size\": 1,\n",
    "                                        \"sort\": [ { \"_uid\" : { \"order\" : \"desc\"} } ]\n",
    "                                        })\n",
    "    return res['hits']['hits'][0][\"_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "6\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "res = es.search(index=\"logstash-001\", body={\"query\": {\"match_all\": {}}})\n",
    "#print(\"Got %d Hits:\" % res['hits']['total'])\n",
    "ox=[]\n",
    "for hit in res['hits']['hits']:\n",
    "    print((hit['_source']['id']))\n",
    "    #print(hit['_source']['author'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_shards': {'failed': 0, 'successful': 5, 'total': 5},\n",
       " 'hits': {'hits': [{'_id': 'AVpLO4vO8bU-6iaIcn13',\n",
       "    '_index': 'logstash-001',\n",
       "    '_score': 1.0,\n",
       "    '_source': {'@timestamp': '2017-02-17T08:41:16.592Z',\n",
       "     '@version': '1',\n",
       "     'content': 'บริษัท ทิ พยู ไพล์ จำกัด(พม่า) จับมือ บริษัท ฮัจยี กรุ๊ป จำกัด(ไทย) ร่วมลงทุนกว่า 78 โครงการ พัฒนาเมืองเย รัฐมอญ สาธารณรัฐสหภาพเมียนมาร์ หลังรัฐบาลกลางเมียนมาร์ไฟเขียวอนุมัติโครงการ และทุกโครงการพร้อมเดินหน้าลงมือดำเนินการในเร็วๆ นี้',\n",
       "     'host': '999-PC',\n",
       "     'id': '5',\n",
       "     'message': '5,บริษัท ทิ พยู ไพล์ จำกัด(พม่า) จับมือ บริษัท ฮัจยี กรุ๊ป จำกัด(ไทย) ร่วมลงทุนกว่า 78 โครงการ พัฒนาเมืองเย รัฐมอญ สาธารณรัฐสหภาพเมียนมาร์ หลังรัฐบาลกลางเมียนมาร์ไฟเขียวอนุมัติโครงการ และทุกโครงการพร้อมเดินหน้าลงมือดำเนินการในเร็วๆ นี้,strong\\r',\n",
       "     'path': 'D:/search/logstash-5.2.1/bin/industry4.csv',\n",
       "     'sentiment': 'strong',\n",
       "     'type': 'industry4'},\n",
       "    '_type': 'industry4'},\n",
       "   {'_id': 'AVpLO4vO8bU-6iaIcn14',\n",
       "    '_index': 'logstash-001',\n",
       "    '_score': 1.0,\n",
       "    '_source': {'@timestamp': '2017-02-17T08:41:16.594Z',\n",
       "     '@version': '1',\n",
       "     'content': 'รองนายกรัฐมนตรีแจงเอกชน ชี้เป็นช่วงเวลาที่ทุกชาติเผชิญความท้าทาย ยกความร่วมมือระหว่างเอเชียจะสร้างพลังขับเคลื่อนทางเศรษฐกิจที่ไม่มีใครเทียบได้ แนะค้นหาจุดแข็งเพื่อเชื่อมโยงสู่ความรุ่งโรจน์ในภูมิภาค ลั่นทำไทยเป็นศูนย์กลางการผลิตอุตสาหกรรมและบริการ กระจายสินค้าและการผลิตได้ ยันรัฐมุ่งมั่นลงทุนโครงสร้างพื้นฐาน รองรับการยกระดับเขตเศรษฐกิจพิเศษ สร้างประโยชน์และความรุ่งเรืองกับทุกๆ ชาติ พร้อมดูแลนักลงทุนอย่างดีที่สุด',\n",
       "     'host': '999-PC',\n",
       "     'id': '6',\n",
       "     'message': '6,รองนายกรัฐมนตรีแจงเอกชน ชี้เป็นช่วงเวลาที่ทุกชาติเผชิญความท้าทาย ยกความร่วมมือระหว่างเอเชียจะสร้างพลังขับเคลื่อนทางเศรษฐกิจที่ไม่มีใครเทียบได้ แนะค้นหาจุดแข็งเพื่อเชื่อมโยงสู่ความรุ่งโรจน์ในภูมิภาค ลั่นทำไทยเป็นศูนย์กลางการผลิตอุตสาหกรรมและบริการ กระจายสินค้าและการผลิตได้ ยันรัฐมุ่งมั่นลงทุนโครงสร้างพื้นฐาน รองรับการยกระดับเขตเศรษฐกิจพิเศษ สร้างประโยชน์และความรุ่งเรืองกับทุกๆ ชาติ พร้อมดูแลนักลงทุนอย่างดีที่สุด,strong\\r',\n",
       "     'path': 'D:/search/logstash-5.2.1/bin/industry4.csv',\n",
       "     'sentiment': 'strong',\n",
       "     'type': 'industry4'},\n",
       "    '_type': 'industry4'},\n",
       "   {'_id': 'AVpLO4vO8bU-6iaIcn15',\n",
       "    '_index': 'logstash-001',\n",
       "    '_score': 1.0,\n",
       "    '_source': {'@timestamp': '2017-02-17T08:41:16.597Z',\n",
       "     '@version': '1',\n",
       "     'content': 'รัฐติดเครื่องอีอีซีเต็มสูบ กระทรวงอุตสาหกรรม-การนิคมใช้ ม.44 ตั้ง \"ศูนย์บริการเบ็ดเสร็จ\" จุดเดียวให้บริการนักลงทุนได้ทุกเรื่อง ตั้งแต่การใช้ที่ดิน-การตั้งโรงงาน-การร่วมทุนรัฐ/เอกชน-EIA/HIA-การอนุญาตทำงาน บีโอไอดึงธุรกิจยักษ์ \"หัวเว่ย-แอร์บัส-อะยิโนโมะโต๊ะ-โรลส์-รอยซ์\" หนุนอีอีซีแจ้งเกิด',\n",
       "     'host': '999-PC',\n",
       "     'id': '7',\n",
       "     'message': '7,\"รัฐติดเครื่องอีอีซีเต็มสูบ กระทรวงอุตสาหกรรม-การนิคมใช้ ม.44 ตั้ง \"\"ศูนย์บริการเบ็ดเสร็จ\"\" จุดเดียวให้บริการนักลงทุนได้ทุกเรื่อง ตั้งแต่การใช้ที่ดิน-การตั้งโรงงาน-การร่วมทุนรัฐ/เอกชน-EIA/HIA-การอนุญาตทำงาน บีโอไอดึงธุรกิจยักษ์ \"\"หัวเว่ย-แอร์บัส-อะยิโนโมะโต๊ะ-โรลส์-รอยซ์\"\" หนุนอีอีซีแจ้งเกิด\",medium\\r',\n",
       "     'path': 'D:/search/logstash-5.2.1/bin/industry4.csv',\n",
       "     'sentiment': 'medium',\n",
       "     'type': 'industry4'},\n",
       "    '_type': 'industry4'}],\n",
       "  'max_score': 1.0,\n",
       "  'total': 3},\n",
       " 'timed_out': False,\n",
       " 'took': 3}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_result(idx,idd):\n",
    "    res = es.search(index=idx, body={  \"query\": {\n",
    "        \"match\" : {\"id\" : idd } } })\n",
    "        \n",
    "    for hit in res['hits']['hits']:\n",
    "        tk=token_item(hit['_source']['content'])\n",
    "        st=hit['_source']['sentiment']\n",
    "        return (tk,st)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['บริษัท',\n",
       "  'ทิ',\n",
       "  'พ',\n",
       "  'ยู',\n",
       "  'ไพล์',\n",
       "  'จำกัด',\n",
       "  'พม่า',\n",
       "  'จับ',\n",
       "  'มือ',\n",
       "  'บริษัท',\n",
       "  'ฮัจยี',\n",
       "  'กรุ๊ป',\n",
       "  'จำกัด',\n",
       "  'ไทย',\n",
       "  'ลงทุน',\n",
       "  '78',\n",
       "  'โครงการ',\n",
       "  'พัฒนา',\n",
       "  'เมืองเย',\n",
       "  'รัฐ',\n",
       "  'มอญ',\n",
       "  'สาธารณรัฐ',\n",
       "  'สหภาพ',\n",
       "  'เมีย',\n",
       "  'นมาร์',\n",
       "  'รัฐบาล',\n",
       "  'กลาง',\n",
       "  'เมีย',\n",
       "  'น',\n",
       "  'มาร์ไฟเขียว',\n",
       "  'อนุมัติ',\n",
       "  'โครงการ',\n",
       "  'โครงการ',\n",
       "  'เดิน',\n",
       "  'หน้า',\n",
       "  'ลงมือ',\n",
       "  'ดำเนิน',\n",
       "  'เร็ว',\n",
       "  'ๆ'],\n",
       " 'strong')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_result(\"logstash-001\",5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index=\"logstash-001\"\n",
    "res = es.search(index, body={\"query\": {\"match_all\": {}}})\n",
    "#print(\"Got %d Hits:\" % res['hits']['total'])\n",
    "ox=[]\n",
    "for hit in res['hits']['hits']:\n",
    "    nid=hit['_source']['id']\n",
    "    tk=get_result(\"logstash-001\",nid)\n",
    "    ox.append(tk)\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['บริษัท', 'ทิ', 'พ', 'ยู', 'ไพล์', 'จำกัด', 'พม่า', 'จับ', 'มือ', 'บริษัท', 'ฮัจยี', 'กรุ๊ป', 'จำกัด', 'ไทย', 'ลงทุน', '78', 'โครงการ', 'พัฒนา', 'เมืองเย', 'รัฐ', 'มอญ', 'สาธารณรัฐ', 'สหภาพ', 'เมีย', 'นมาร์', 'รัฐบาล', 'กลาง', 'เมีย', 'น', 'มาร์ไฟเขียว', 'อนุมัติ', 'โครงการ', 'โครงการ', 'เดิน', 'หน้า', 'ลงมือ', 'ดำเนิน', 'เร็ว', 'ๆ'], 'strong'), (['รอง', 'นายกรัฐมนตรี', 'แจง', 'เอกชน', 'ชี้', 'เวลา', 'ชาติ', 'เผชิญ', 'ท้าทาย', 'ยก', 'ร่วมมือ', 'เอเชีย', 'สร้าง', 'พลัง', 'ขับเคลื่อน', 'เศรษฐกิจ', 'ใคร', 'เทียบ', 'แนะ', 'ค้น', 'หา', 'จุด', 'แข็ง', 'เชื่อม', 'โยง', 'สู่', 'รุ่งโรจน์', 'ภูมิภาค', 'ลั่น', 'ทำ', 'ไทย', 'ศูนย์', 'กลาง', 'ผลิต', 'อุตสาหกรรม', 'บริการ', 'กระจาย', 'สินค้า', 'ผลิต', 'ยัน', 'รัฐ', 'มุ่ง', 'มั่น', 'ลงทุน', 'โครงสร้าง', 'พื้นฐาน', 'รอง', 'ยก', 'ระดับ', 'เขต', 'เศรษฐกิจ', 'พิเศษ', 'สร้าง', 'ประโยชน์', 'รุ่งเรือง', 'ทุกๆ', 'ชาติ', 'ดูแล', 'ลงทุน', 'ดี'], 'strong'), (['บี', 'โอ', 'ไอ', 'ชะลอ', 'แผนการ', 'อนุมัติ', 'งบประมาณ', 'ลงทุน', 'รอ', 'ชัดเจน'], 'medium'), (['สมาคม', 'ผู้', 'รถยนต์', 'ตัวเลข', 'ชะลอ', 'ตัว', 'กำลัง', 'ซื้อ', 'ตกต่ำ'], 'mediumดสร้างสรรค์พัฒนาประเทศให้ก้าวสู่ยุค Thailand 4.0'), (['รัฐ', 'ติดเครื่อง', 'อี', 'อี', 'ซี', 'เต็ม', 'สูบ', 'กระทรวง', 'อุตสาหกรรม', 'นิคม', 'ใช้', 'ม', 'ศูนย์', 'บริการ', 'เบ็ดเสร็จ', 'จุด', 'บริการ', 'ลงทุน', 'เรื่อง', 'ใช้', 'ที่ดิน', 'โรงงาน', 'ทุน', 'รัฐ', 'เอกชน', 'eia', 'hia', 'อนุญาต', 'ทำ', 'งาน', 'บี', 'โอ', 'ไอ', 'ดึง', 'ธุรกิจ', 'ยักษ์', 'หัวเว่ย', 'แอร์บัส', 'อะยิโน', 'โมะโต๊ะ', 'โรลส์', 'รอยซ์', 'หนุน', 'อี', 'อี', 'ซี', 'แจ้ง', 'เกิด'], 'medium'), (['ธนาคาร', 'ระงับ', 'โครงการ', 'ลงทุน', 'ธุรกิจ', 'รถยนต์', 'สภาวะ', 'เศรษฐกิจ', 'ฟื้นตัว'], 'medium')]\n"
     ]
    }
   ],
   "source": [
    "print(ox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_set = nltk.classify.apply_features(extract_features, ox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_features = get_word_features(get_words_in_tweets(ox))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "คณะรัฐมนตรีอนุมัติงบประมาณลงทุนเขตเศรษฐกิจพิเศษ : strong signal\n"
     ]
    }
   ],
   "source": [
    "#  ใส่ข้อความตรงอักษรสีแดง ด้านล่างนี้ #\n",
    "\n",
    "steep= 'คณะรัฐมนตรีอนุมัติงบประมาณลงทุนเขตเศรษฐกิจพิเศษ'\n",
    "\n",
    "# ระบุ Catagory  : Social ,Technology, Economic, Environment, Polotic #\n",
    "\n",
    "catatory = \"Environment\"\n",
    "\n",
    "\n",
    "steep=steep.replace(\",\",\"\")\n",
    "steepx=segment(steep)\n",
    "#myString = \" \".join(steepx)\n",
    "\n",
    "answer=(classifier.classify(extract_features(myString.split())))\n",
    "print (steep+\" : \"+classifier.classify(extract_features(myString.split()))+\" signal\")\n",
    "\n",
    "###\n",
    "#date=strftime(\"%Y-%m-%d\", gmtime())\n",
    "#text_file = codecs.open(\"D:/search/logstash-5.0.0/bin/industry4/Output.csv\", \"a\", 'UTF-8')\n",
    "#text_file.write(date+\",\"+catatory+\",\"+steep+\",\"+str(answer)+\"\\n\")\n",
    "#text_file.close()\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "คณะรัฐมนตรีเห็นชอบโครงการพัฒนาเขตเศรษฐกิจพิเศษ\r\n",
      " : medium signal\n",
      "\n",
      "บีโอไออนุมัติให้ผู้ประกอบการด้านอุตสาหกรรมรถยนต์ ขยายโรงงานในเขตเศรษฐกิจพิเศษ\r\n",
      " : medium signal\n",
      "\n",
      "สมาคมธนาคารรอความชัดเจนก่อนผลักดันแผนการลงทุนในระยะ 5 ปีข้างหน้า\r\n",
      " : medium signal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file =codecs.open(\"test-data.txt\",'r',\"utf-8\")\n",
    "for me in file:\n",
    "    steep=me.replace(\",\",\"\")\n",
    "    steepx=segment(me)\n",
    "    myString = \" \".join(steepx)\n",
    "    print (steep+\" : \"+classifier.classify(extract_features(myString.split()))+\" signal\")\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
